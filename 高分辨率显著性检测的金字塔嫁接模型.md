# <center>Pyramid Grafting Network for One-Stage High Resolution Saliency Detection

### 摘要
由于采样深度和感受野大小之间的矛盾，大多数根据低分辨输入设计的SOD模型在高分辨率图像中表现不佳，本文提出一种金字塔嫁接网络。使用transformer和CNN主干分别从不同分辨率的图像中提取特征，然后将特征从transformer分支嫁接到CNN分支，与此同时提出一种基于注意的分叉模型嫁接模块，使CNN分支能够在解码过程中，在不同信源特征的引导下，更全面地组合破碎的细节信息，此外还设计了一个注意引导丢失来明确监督交叉嫁接模块生成注意矩阵，以帮助网络更好地与来自不同模型的注意进行交互。

### 困境

当前主流的SOD模型遇到高分辨率的图像，为了减少内存的开销往往会将图像先下采样然后对输出结果上采样已恢复原始分辨率，由于现在的SOD模型都是使用编码器-解码器的方式设计的，随着分辨率的大幅度提高，提取的特征大小会增加，但是网络的感受野是固定的，使得相对感受野变小，最终导致无法捕获对任务至关重要的全局语义。
<div align="center"><img src="image\高分辨率下的传统模型困境.PNG"></div> 

目前对于高分辨率SOD方法有两种主流：HRSOD和DHQSOD，其中HRSOD将整个过程分为全局阶段，局部阶段和重组阶段，全局阶段为局部阶段和作物过程提供指导。DHSOD将SOD任务分解为分类任务和回归任务，这两个任务通过他们提出的trimap和不确定性损失连接起来，它们生成具有清晰边界的相对较好的显著性贴图。但是这两者都是使用多阶段架构，将SOD分为语义(低分辨率)和细节(高分辨率)两个阶段。由此引出两个问题：
>- 阶段间语境语义迁移不一致，在前一个阶段获得的中间映射被输入到最后一个阶段，同时错误也被传递，由此后续细化阶段可能将继续放大错误
>- 耗时，与单阶段相比，多阶段方法不仅难以并行且参数过多，模型运行运行速度较慢

### 高分辨率SDO发展

Zeng等人[Towards High-Resolution Salient Object Detection](https://ieeexplore.ieee.org/document/9008818)提出了一种高分辨率显著目标检测范式，使用GSN提取语义信息，使用APS引导的LRN优化局部细节，最后使用GLFN进行预测融合。他们还提供了第一个高分辨率显著目标检测数据集（HRSOD）。Tang等人[Disentangled high quality salient object detection](https://ieeexplore.ieee.org/document/9709916)提出，显著目标检测应分为两项任务。他们首先设计LRSCN以在低分辨率下捕获足够的语义并生成trimap。通过引入不确定性损失，所设计的HRRN可以对第一阶段使用低分辨率数据集生成的trimap进行细化。然而，它们都使用多级体系结构，这导致推理速度较慢，难以满足某些实际应用场景。更严重的问题是网络之间的语义不一致。

使用常用的SOD数据集通常分辨率较低，用他们来训练高分辨率网络和评估高质量分割存在以下几点缺点:
>- 图像分辨率低导致细节不足
>- 注释边缘的质量较差
>- 注释的更加精细级别不够令人满意

当前可用的高分辨率数据集是HRSOD，但是HRSOD数据集图像数量有限,严重影响模型的泛化能力。

### Staggered Grafting Framework


网络框架如图所示：
<div align="center"><img src="image\Pyramid_Grafting_network.PNG"></div> 

由两个编码器和一个解码器构成，使用Swim transformer和ResNet18作为编码器，transformer编码器能够在低分辨率情况下获得准确的全局语义信息，卷积编码器能够在高分辨率输入下获得丰富的细节信息，不同模型之间的提取的特征可能是互补的，可以获得更多的有效特征。

在编码的过程中，向两个编码器馈送不同分辨率的图像，并行获取全局语义信息和详细信息。解码分为三个过程，一个是Swim解码，一个是嫁接编码，最后是交错结构的ResNet解码，在第二个子阶段的解码特征是从跨模态移植模块产生的，其中全局语义信息从Swin分支移植到ResNet分支，跨模态移植模块还会处理一个名为CAM的矩阵进行监督

### 交叉模型迁移模块(CMGM)

作用：移植由两个编码器提取的特征，对于transformer所提取的特征$f_{S_2}$能够远距离捕获信息，具有全局语义信息。使用ResNet所得到的$f_{R_5}$有更好的局部信息，也就是更丰富的细节信息。但是由于特征大小和感受野之间的差异，在$f_{R_5}$中有更多的噪声。

使用常见的融合方法：如逐元素相加和相乘的适用情况限制在显著预测和不同特征生成的预测至少有一部分是对的情况下，否则就是一种错误的适用方式，且这种操作都只关注于有限的局部信息，导致没法实现自我纠错。

作者提出使用CMGM重新计算ResNet特征和Transformer特征之间的逐点关系，将全局语义信息通过transformer分支转移到ResNet分支，从而弥补常见的错误，通过计算$E=|G-P| \in [0,1]$得到误差图

### <center> CMGM纠错效果图
<div align="center"><img src="image\CMGM纠错.PNG"></div> 


### <center> CMGM网络结构
<div align="center"><img src="image\CMGM网络结构.PNG"></div>

### <center> 实验结果
<div align="center"><img src="image\PGNet定量实验结果.PNG"></div>

### <center>可视化</center>
<div align="center"><img src="image\PGNet可视化结果.PNG"></div>