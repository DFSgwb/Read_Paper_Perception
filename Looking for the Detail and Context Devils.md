# <center>Looking for the Detail and Context Devils:High-Resolution Salient Object Detection </center>

缺乏显著对象的边界细节和语义上下文是低分辨率SOD数据集的一大弊端，本文设计了一个端到端的学习框架，称为DRFNet,使用一个共享特征提取器和两个有效的细化头构成。通过解耦细节和上下文信息，一个细化头采用全局感知和特征金字塔，在不增加太多计算负担的情况下，提升空间细节信息，从而缩小高级语义和低级细节之间的差距，另一个细化头采用混合扩张卷积块和分组上采样，这在提取上下文信息方面非常有效，基于双重细化，使得实现扩大感受野并从高分辨率图像中获取更多的判别特征。

高分辨率图像具有一个突出的特点包含更多可以覆盖范围和形状的结构对象和更多的细节信息。一方面高级上下文特征更适合检测大而混乱的对象，而小对象则受益于低级精细特征。不同层次特征的结合将为语义定位和细节增强提供更丰富的信息。

现有的基于FCN结构的方法一个缺点就是特征通常是以粗到精细的方式集成，它缺乏获取足够的局部和全局上下文信息或远程依赖关系的能力。导致不显眼的对象和混淆区域的准确性较差。大量的使用卷积操作使得对于算力和内存的要求变得极高，但如果将输入图像限制为相对较低的分辨率，又阻碍了细节感知和高分辨的实际需求。

现有的高分辨率图像像素级标记方法大致分为三大类，
>- 1首先将高分辨率图像裁剪为低分辨图像，然后预测低分辨率结果并将其结果插值为原始图像大小。这种操作虽然简单但是图像空间细节的丢失是不可避免，导致出现对物体边界的错误预测
>- 2设计轻型编码器-解码器网络,通过特征融合层次特征，之间提高空间分辨率并恢复一些缺少的细节，但是这种由于连续的下采样操作会带来空间信息的丢失且缺乏足够的对象的感受野
>- 3 引入具有多个分支的不对称网络,每个分支以不同分辨率运行，即低分辨率图像中提取全局信息，高分辨率图像中提取精细细节，但是如何在不同分支上整合全局和局部信息还没一个很好的方法，由于高级语义和低级细节之间的差距，不好的融合方式可能使得它们在预测中出现奇怪的预测区域

### <center>常见的HRSOD网络架构</center>
<div align="center"><img src="image\三种常用的HR网络架构.PNG"></img></div>


### <center>本文网络结构</center>
<div align="center"><img src="image\DRFNet.PNG"></img></div>

### 共享特征提取器
采用修改后的VGG-16和ResNet-18作为共享特征提取器

### Detail Refinement Head

DRH包括三个关键块：

>- 1卷积特征缩减块(CFRB):该块旨在缩小多尺度深度特征的维数，本质上就是一个$1\times1$的卷积块，后面是批归一化和Relu激活函数，为减少高分辨率图像的计算和内存需求，卷积滤波器的数量设为为32
>- 2深度特征上采样块(DFUB):采用C组的反卷积进行上采样，通过适当的上采样率，可以放大较深层的输出特征以匹配较浅层产生的特征，且进一步减少计算量
>- 3全局感知特征交互块(GFIB)：由于接受域有限，无法获取足够的全局信息，为表达增强表现能力，首先对CFRB和DFUB的特征进行级联全局平均池化。然后将其转发到全连接层以生成全局权重向量,整个过程可以表示为
$$\Large \alpha_G = \sigma(W_1*GAP([F_C,F_D])+b)$$
$$\Large F_R=g(W_2*[F_C,F_D]+b)$$
$$\Large F_G = \alpha_G\odot F_R$$

### Context Refinement Head
在直接堆叠或使用金字塔结构扩大感受野的策略中具有两个非常明显的缺点。1：计算量大，占用内存，不适合高分辨率图像。2：缺乏捕获足够多尺度局部上下文信息的能力，导致对于不显眼的对象的准确性较差本文提出的CRH使用混合膨胀卷积和分组上采样组成。具体的来说就是使用一个混合扩张卷积块和一个分组上采样组成
