# <center>Towards High-Resolution Salient Object Detection</center>

### 摘要
基于深度神经网络的方法在显着目标检测方面取得了重大突破.但是,它们通常仅限于低分辨率(400×400像素或更小)的输入图像。几乎没有努力训练神经网络直接处理高分辨率图像中的显着对象分割。本文推动了高分辨率显着性检测，并贡献了一个新的数据集,高分辨率显着性对象检测HRSOD。据我们所知,HRSOD是迄今为止第一个高分辨率显着性检测数据集。
作为另一个贡献,我们还提出了一种新颖的方法,它结合了全局语义信息和局部高分辨率细节.以解决这一具有挑战性的任务。更具体地说，我们的方法由全局语义网络(GSN)、局部细化网络(LRN)和全局-局部融合网络(GLFN)组成。GSN基于下采样的整幅图像提取全局语义信息。LRN以GSN的结果为指导,重点关注一些局部区域,逐步产生高分辨率的预测。进一步提出 GLFN 以加强空间一致性并提高性能。实验表明,我们的方法在高分辨率显着性数据集上大大优于现有的最先进方法,并且在一些广泛使用的显着性基准上实现了与它们相当甚至更好的性能。

### Introduction
低分辨率的显著目标检测算法直接迁移到高分辨图像中,将使得预测的结果出现一个明显的问题：边界模糊的极为明显。如下图所示
### <center>边界模糊对比</center>
<div align="center"><img src="image\边界模糊.PNG"></div>

对于高分辨显著性检测有最直观的三种方法,一是简单的增加输入大小,以在一系列池化操作后保持相对较高分辨率和对象细节,但是较大的输入会导致内存使用量显著增加,此外，是否可以通过反向传播有效地从如此深的网络中的较低层提取细节仍然是一个问题。第二种的方法是将输入划分为补丁块进行预测,然而这种方法非常耗时,且容易受到背景噪音的影响，第三种是使用一些后处理方法,例如CRF和图割技术,但是目前没有多少作品这样使用。

### High-Resolution Saliency Detection Dataset
当前显著目标检测数据集缺点:数据集中和所有图像分辨率都非常有限,这些低分辨图像已经不能代表当前图像处理应用所遇到的图像级别,其次为了减少用户的负担,必须在边界区域输出精度极高的掩码,但是现有的显著性检测数据集中的图像不足以为训练DNN提供丰富的对象边界细节。当前广泛使用的显著性数据集在标注质量方面也存在一些问题,例如未能覆盖所有的显著性区域,包括背景干扰到前景标注或轮廓精度低等，例如下图所示：
<div align="center"><img src="image\低分辨率图像存在的问题.PNG"></img></div>

提出首个HRSOD数据集，其中包含1610幅训练图像和400幅测试图像。

### Method

该网络由三部分构成：

    >全局语义网络(GSN)：从全局角度提取语义信息
    >局部优化网络(LRN)：用于细化不确定子区域
    >全局局部融合网络(GLFN)：将高分辨率图像作为输入,进一步增强GSN和LRN融合预测空间一致性

具体过程就是：首先将$\{ X_i=(I_i,L_i)_{i=1}^N \}$作为训练输入,其中$I_i$表示训练图像,$L_i$表示逐像素显著性标签。首先通过GSN将输入图像得到一个粗略的显著图$F_i$,计算方式为:
$$\Large F_i = UP(GSN(DS(I_i),\theta))$$
其中$DS(\cdot)$下采样到$384 \times 384$ ,$DP(\cdot)表示上采样到原始大小$。$\theta$表示GSN中的全部参数，然后将$I_i$放到补丁采样模块(APS)生成子图像$\{ P_{m}^{I_i} \}_{m=1}^M$,这些子图像是关注不确定区域的，然后子图通过一个LRN前馈得到一个细化的显著图像$R_m^{I_i}$语义指导从GSN引入到LRN,最后将两者的输出融合并通过GLFN前馈用于最终预测出结果。这个过程可以表示为
$$\large \{ R_{m}^{I_i}\}_{m=1}^M=LRN(\{ P_{m}^{I_i} \}_{m=1}^M,\phi)$$
$$\Large S_i = GLFN(I_i,Fuse(\{ R_{m}^{I_i}\}_{m=1}^M,F_i),\psi)$$
### <center>网络架构
<div align="center"><img src="image\GSN和LRN网络架构.PNG"></img></div>


该模型构建在FCN架构之上,使用带有预训练的16层VGG，为保持更高的分辨率，需要放弃conv5_3之后的所有层，为扩大感受野，采用扩张卷积实现，传统的基于patch的滑动窗口的方式来推断图像中的每一个patch非常耗时,因此提出通过分层预测方式(GSN用于容易区域,LRN用于较难区域)，使用patch采样方式，以GSN的结果作为指导生成关注不确定区域的子图像，注意力图中的不确定像素$A_i$可以表示为：
$$\Large A_{i}(x,y)=\begin{cases}
1 & T_{1}<F_{i}(x,y)<T_2 \\
0 & otherwise \\
\end{cases}$$
为节省内存，提出一个轻量级的$Global-Local\quad Fusion\quad Network$来进行GSN和LRN信息的融合
